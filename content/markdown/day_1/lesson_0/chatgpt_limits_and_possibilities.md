---
author: [EBSCO Information Services, Timothy A. Thompson ‚çù @timathom @timathom@indieweb.social]
---

# ChatGPT: Limits and Possbilities

-   That is the traditional explanation.

-   However, Large Language Models such as ChatGPT have called this explanation into question.

-   ChatGPT was trained in large part on the [Common Crawl](https://commoncrawl.org/), a massive dataset of web pages compiled since 2011.

-   Does ChatGPT undermine the linked data thesis?

-   Can machine understanding be achieved **without** semantics, by learning complex probability distributions from unstructured data?


**Previous topic:**[Machine Understanding](../../day_1/lesson_0/machine_understanding_2.md)

**Next topic:**[ChatGPT: Limits and Possbilities](../../day_1/lesson_0/semantic_web_won.md)

