---
author: [EBSCO Information Services, Timothy A. Thompson ⍝ @timathom ⍝ @timathom@indieweb.social]
---

# ChatGPT: Limits and Possbilities

![Tweet by Adrian Gschwend showing a screenshot of a table with statistics about websites in the Common Crawl corpus, showing that 1518609988 webpages (about 50% of the total) include RDF triples.](../../submaps/../img/introduction/common_crawl_tweet.png "Tweet by Adrian Gschwend (@linkedktk)")

**Previous topic:**[ChatGPT: Limits and Possbilities](../../day_1/lesson_0/chatgpt_limits_and_possibilities.md)

**Next topic:**[ChatGPT: Limits and Possbilities](../../day_1/lesson_0/snow_white_problem.md)

## Summary

-   Structured data in the form of RDF triples is already embedded on 50% of pages on the web.
-   As a result, ChatGPT has already been able to learn from and incorporate structured data semantics.

